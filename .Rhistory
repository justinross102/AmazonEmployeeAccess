batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "First", "Second", "Third", "Fourth", "Fifth", "Sixth", "Seventh", "Eigth", "Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,12,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
batting
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "First", "Second", "Third", "Fourth", "Fifth", "Sixth", "Seventh", "Eigth", "Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,12,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
batting <- batting %>%
mutate(across(
where(is.character) & !startsWith(names(.), "Date"),
~sub("-.*", "", .)
))
batting <- batting %>%
mutate(across(
where(~is.character(.) & !startsWith(names(.), "Date")),
~sub("-.*", "", .)
))
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "First", "Second", "Third", "Fourth", "Fifth", "Sixth", "Seventh", "Eigth", "Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,12,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
batting
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "First", "Second", "Third", "Fourth", "Fifth", "Sixth", "Seventh", "Eigth", "Ninth")
# clean
batting <- batting %>%
as_tibble(lapply(batting, function(column) sub("-.*", "", column)))
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "First", "Second", "Third", "Fourth", "Fifth", "Sixth", "Seventh", "Eigth", "Ninth")
# clean
batting <- batting %>%
as_tibble(lapply(batting, function(column) sub("-.*", "", column))) %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,12,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
batting
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "First", "Second", "Third", "Fourth", "Fifth", "Sixth", "Seventh", "Eigth", "Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,12,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
batting
for (col in names(batting)[-1]) {
data[[col]] <- gsub("-.*", "", batting[[col]])
}
for (col in names(batting)[-1]) {
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
rm(list = ls())
get_html_table <- function(url, index, header = T){
df <- url %>%
read_html() %>%
html_elements("table") %>%
html_table(header=header) %>%
.[[index]]
df
}
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "C", "First_B", "Second_B", "Third_B", "SS", "LF", "CF", "RF", "P", "DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,13,2,3,4,5,6,7,8,9,10,11)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
defense
rm(list=ls())
get_html_table <- function(url, index, header = T){
df <- url %>%
read_html() %>%
html_elements("table") %>%
html_table(header=header) %>%
.[[index]]
df
}
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,13,2,3,4,5,6,7,8,9,10,11)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
defense
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Team = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,12,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
for (col in names(batting)[-1]) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
website = "https://www.baseball-reference.com/teams/PHI/2023-schedule-scores.shtml"
phillies_games <- get_html_table(website, 1)
# clean
colnames(phillies_games) <- c("Game", "Date", "boxscore", "Team", "Location", "Opp", "Outcome", "R", "RA", "Inn", "W_L", "Rank",
"GB", "Win", "Loss", "Save", "Time", "D_N", "Attendance", "cLI", "Streak", "Orig_Scheduled")
phillies_games <- as_tibble(lapply(phillies_games, function(Outcome) sub("-.*", "", Outcome)))
phillies_games <- phillies_games %>%
filter(Game != "Gm#", # get rid of monthly headers
boxscore != "preview") %>%  # get rid of games that haven't been played yet
mutate(Location = as.factor(if_else(Location == "@", "Away", "Home")),
D_N = as.factor(if_else(D_N == "D", "Day", "Night")),
Date = as.Date(Date, format = "%A, %b %d"),
Opp = as.factor(Opp),
Outcome = as.factor(Outcome)) %>%
select(c(2,5,18,6,7))
phillies_games
merged_data <- merge(phillies_games, defense, by = c("Date", "Opp"), all = TRUE)
defense
batting
phillies_games
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,13,2,3,4,5,6,7,8,9,10,11)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
rm(list = ls())
get_html_table <- function(url, index, header = T){
df <- url %>%
read_html() %>%
html_elements("table") %>%
html_table(header=header) %>%
.[[index]]
df
}
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,13,2,3,4,5,6,7,8,9,10,11)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
defense
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,12,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
defense
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
defense
url_defense <- "https://www.baseball-reference.com/teams/PHI/2023-lineups.shtml"
defense <- get_html_table(url_defense,1)
colnames(defense) <- c("Opp", "PHI_C", "PHI_First_B", "PHI_Second_B", "PHI_Third_B", "PHI_SS", "PHI_LF",
"PHI_CF", "PHI_RF", "PHI_P", "PHI_DH")
# clean
defense <- defense %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(12,1,2,3,4,5,6,7,8,9,10,11)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
defense
merged_data <- merge(phillies_games, defense, by = c("Date", "Opp"), all = TRUE)
website = "https://www.baseball-reference.com/teams/PHI/2023-schedule-scores.shtml"
phillies_games <- get_html_table(website, 1)
# clean
colnames(phillies_games) <- c("Game", "Date", "boxscore", "Team", "Location", "Opp", "Outcome", "R", "RA", "Inn", "W_L", "Rank",
"GB", "Win", "Loss", "Save", "Time", "D_N", "Attendance", "cLI", "Streak", "Orig_Scheduled")
phillies_games <- as_tibble(lapply(phillies_games, function(Outcome) sub("-.*", "", Outcome)))
phillies_games <- phillies_games %>%
filter(Game != "Gm#", # get rid of monthly headers
boxscore != "preview") %>%  # get rid of games that haven't been played yet
mutate(Location = as.factor(if_else(Location == "@", "Away", "Home")),
D_N = as.factor(if_else(D_N == "D", "Day", "Night")),
Date = as.Date(Date, format = "%A, %b %d"),
Opp = as.factor(Opp),
Outcome = as.factor(Outcome)) %>%
select(c(2,5,18,6,7))
merged_data <- merge(phillies_games, defense, by = c("Date", "Opp"), all = TRUE)
view(merged_data)
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
for (col in names(batting)[-1]) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
url_batting <- "https://www.baseball-reference.com/teams/PHI/2023-batting-orders.shtml"
batting <- get_html_table(url_batting,1)
colnames(batting) <- c("Opp", "PHI_First", "PHI_Second", "PHI_Third", "PHI_Fourth",
"PHI_Fifth", "PHI_Sixth", "PHI_Seventh", "PHI_Eigth", "PHI_Ninth")
# clean
batting <- batting %>%
mutate(Date = as.Date(str_extract(Opp, "\\w{3},\\d{1,2}/\\d{1,2}"), format = "%a,%m/%d"),
Opp = str_extract(Opp, "(?<=\\sat\\s|\\svs\\s)[A-Z]+")) %>%
select(c(11,1,2,3,4,5,6,7,8,9,10)) %>%
mutate(across(where(is.character), as.factor)) %>%
head(162)
for (col in names(batting)[-1]) { # remove - from player names
batting[[col]] <- gsub("-.*", "", batting[[col]])
}
batting
all_games <- merge(merged_data, batting, by = c("Date", "Opp"), all = TRUE)
view(all_games)
all_games
install.packages('caret')
library(caret)
index <- createDataPartition(all_games$Outcome, p = 0.8, list = FALSE)
# Split the data into training and test sets
train <- all_games[index, ]
test <- all_games[-index, ]
train
test
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) # target encoding (must be 2-factor)
library(tidymodels)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) # target encoding (must be 2-factor)
library(embed) # for target encoding
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) # target encoding (must be 2-factor)
# apply the recipe to the data
prepped_recipe <- prep(my_recipe)
# apply the recipe to the data
prepped_recipe <- prep(target_encoding_recipe)
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) # target encoding (must be 2-factor)
# apply the recipe to the data
prepped_recipe <- prep(target_encoding_recipe)
baked <- bake(prepped_recipe, new_data = train) # should have 112 columns
baked
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) # target encoding (must be 2-factor)
# apply the recipe to the data
prepped_recipe <- prep(target_encoding_recipe)
baked <- bake(prepped_recipe, new_data = train) # should have 112 columns
baked
target_encoding_recipe <- recipe(Outcome ~ ., train) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(Outcome)) # target encoding (must be 2-factor)
# apply the recipe to the data
prepped_recipe <- prep(target_encoding_recipe)
baked <- bake(prepped_recipe, new_data = train) # should have 112 columns
baked
view(baked)
rand_forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% # or 1000
set_engine("ranger") %>%
set_mode("classification")
rand_forest_workflow <- workflow() %>%
add_model(rand_forest_mod)
rand_forest_tuning_grid <- grid_regular(mtry(range = c(1, (ncol(train)-1))),
min_n(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
forest_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- rand_forest_workflow %>%
tune_grid(resamples = forest_folds,
grid = rand_forest_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
setwd("~/Documents/BYU/stat348/AmazonEmployeeAccess")
# load libraries ----------------------------------------------------------
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed) # for target encoding
library(ggmosaic)
# load in data ------------------------------------------------------------
train <- vroom("./train.csv") %>%
mutate(ACTION = as.factor(ACTION))
test <- vroom("./test.csv") %>%
select(-1)
predict_and_format <- function(workflow, new_data, filename){
predictions <- workflow %>%
predict(new_data = new_data,
type = "prob")
submission <- predictions %>%
mutate(Id = row_number()) %>%
rename("Action" = ".pred_1") %>%
select(3,2)
vroom_write(x = submission, file = filename, delim=",")
}
my_recipe <- recipe(ACTION ~ ., data = train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>%  # combines categorical values that occur <1% into an "other" value
step_dummy(all_nominal_predictors())  # dummy variable encoding
target_encoding_recipe <- recipe(ACTION ~ ., train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .001) %>%  # combines categorical values that occur <1% into an "other" value
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) # target encoding (must be 2-factor)
install.packages('discrim')
# naive bayes -------------------------------------------------------------
naive_bayes_model <- naive_Bayes(Laplace = tune(),
smoothness = tune()) %>%
set_mode("classification") %>%
set_engine("naivebayes")
naive_bayes_wf <- workflow() %>%
add_recipe(target_encoding_recipe) %>%
add_model(naive_bayes_model)
# naive bayes -------------------------------------------------------------
library(discrim)
naive_bayes_model <- naive_Bayes(Laplace = tune(),
smoothness = tune()) %>%
set_mode("classification") %>%
set_engine("naivebayes") # install discrim library
naive_bayes_wf <- workflow() %>%
add_recipe(target_encoding_recipe) %>%
add_model(naive_bayes_model)
# cross validation
nb_tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5)
## Split data for CV
nb_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- naive_bayes_wf %>%
tune_grid(resamples = nb_folds,
grid = nb_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
install.packages('naivebayes')
library(naivebayes)
## Split data for CV
nb_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- naive_bayes_wf %>%
tune_grid(resamples = nb_folds,
grid = nb_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
# finalize workflow
final_nb_wf <- naive_bayes_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
# find nest tuning parameters
nb_bestTune <- CV_results %>%
select_best("roc_auc")
nb_bestTune
# finalize workflow
final_nb_wf <- naive_bayes_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
predict_and_format(final_nb_wf, test, "./naive_bayes_predictions.csv")
my_recipe
my_recipe <- recipe(ACTION ~ ., data = train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>%  # combines categorical values that occur <1% into an "other" value
step_dummy(all_nominal_predictors())  # dummy variable encoding
naive_bayes_model <- naive_Bayes(Laplace = tune(),
smoothness = tune()) %>%
set_mode("classification") %>%
set_engine("naivebayes") # install discrim library
naive_bayes_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(naive_bayes_model)
# cross validation
nb_tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5)
## Split data for CV
nb_folds <- vfold_cv(train, v = 5, repeats = 1)
# find nest tuning parameters
nb_bestTune <- CV_results %>%
select_best("roc_auc")
# finalize workflow
final_nb_wf <- naive_bayes_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
predict_and_format(final_nb_wf, test, "./naive_bayes_predictions.csv")
naive_bayes_wf <- workflow() %>%
add_recipe(target_encoding_recipe) %>%
add_model(naive_bayes_model)
# cross validation
nb_tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5)
## Split data for CV
nb_folds <- vfold_cv(train, v = 5, repeats = 1)
# find nest tuning parameters
nb_bestTune <- CV_results %>%
select_best("roc_auc")
# finalize workflow
final_nb_wf <- naive_bayes_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
predict_and_format(final_nb_wf, test, "./naive_bayes_predictions.csv")
naive_bayes_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(naive_bayes_model)
# cross validation
nb_tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5)
## Split data for CV
nb_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- naive_bayes_wf %>%
tune_grid(resamples = nb_folds,
grid = nb_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
# find nest tuning parameters
nb_bestTune <- CV_results %>%
select_best("roc_auc")
nb_bestTune
# finalize workflow
final_nb_wf <- naive_bayes_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
predict_and_format(final_nb_wf, test, "./naive_bayes_predictions.csv")
naive_bayes_wf <- workflow() %>%
add_recipe(target_encoding_recipe) %>%
add_model(naive_bayes_model)
# cross validation
nb_tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5)
## Split data for CV
nb_folds <- vfold_cv(train, v = 5, repeats = 1)
## Run the CV
CV_results <- naive_bayes_wf %>%
tune_grid(resamples = nb_folds,
grid = nb_tuning_grid,
metrics = metric_set(roc_auc)) # f_meas, sens, recall, spec, precision, accuracy
# find nest tuning parameters
nb_bestTune <- CV_results %>%
select_best("roc_auc")
# finalize workflow
final_nb_wf <- naive_bayes_wf %>%
finalize_workflow(nb_bestTune) %>%
fit(data = train)
predict_and_format(final_nb_wf, test, "./naive_bayes_predictions.csv")
